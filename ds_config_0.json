{

  "train_batch_size": 64,

  "train_micro_batch_size_per_gpu": 16,

  "gradient_accumulation_steps": 4,

  "bf16": { "enabled": true },
  "wall_clock_breakdown": false,

  "steps_per_print": 1,
  "zero_optimization": { "stage": 1 },
  "pipeline": {

    "activation_checkpoint_interval": 1,

    "use_reentrant": false

  }


}
